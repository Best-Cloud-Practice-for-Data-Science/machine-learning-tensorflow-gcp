{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 2: Estimator API\n",
    "1. Estimator API\n",
    "2. Lab Estimator API\n",
    "3. Train on large datasets with Dataset API\n",
    "4. Lab Scaling up TensorFlow ingest using batching\n",
    "5. Big jobs, Distributed training\n",
    "6. Monitoring with TensorBoard\n",
    "7. Lab Creating a distributed training TensorFlow model with Estimator API\n",
    "8. Quiz Estimator API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Estimator API\n",
    "![ ](img/2-1-01.png)\n",
    "![ ](img/2-1-02.png)\n",
    "![ ](img/2-1-03.png)\n",
    "![ ](img/2-1-04.png)\n",
    "![ ](img/2-1-05.png)\n",
    "![ ](img/2-1-06.png)\n",
    "![ ](img/2-1-07.png)\n",
    "![ ](img/2-1-08.png)\n",
    "![ ](img/2-1-09.png)\n",
    "![ ](img/2-1-10.png)\n",
    "![ ](img/2-1-11.png)\n",
    "![ ](img/2-1-12.png)\n",
    "![ ](img/2-1-13.png)\n",
    "![ ](img/2-1-14.png)\n",
    "![ ](img/2-1-15.png)\n",
    "![ ](img/2-1-16.png)\n",
    "![ ](img/2-1-17.png)\n",
    "![ ](img/2-1-18.png)\n",
    "![ ](img/2-1-19.png)\n",
    "![ ](img/2-1-20.png)\n",
    "![ ](img/2-1-21.png)\n",
    "![ ](img/2-1-22.png)\n",
    "![ ](img/2-1-23.png)\n",
    "![ ](img/2-1-24.png)\n",
    "![ ](img/2-1-25.png)\n",
    "![ ](img/2-1-26.png)\n",
    "![ ](img/2-1-27.png)\n",
    "![ ](img/2-1-28.png)\n",
    "![ ](img/2-1-29.png)\n",
    "![ ](img/2-1-30.png)\n",
    "![ ](img/2-1-31.png)\n",
    "![ ](img/2-1-32.png)\n",
    "![ ](img/2-1-33.png)\n",
    "![ ](img/2-1-34.png)\n",
    "![ ](img/2-1-35.png)\n",
    "![ ](img/2-1-36.png)\n",
    "![ ](img/2-1-37.png)\n",
    "![ ](img/2-1-38.png)\n",
    "![ ](img/2-1-39.png)\n",
    "![ ](img/2-1-40.png)\n",
    "![ ](img/2-1-41.png)\n",
    "![ ](img/2-1-42.png)\n",
    "![ ](img/2-1-43.png)\n",
    "![ ](img/2-1-44.png)\n",
    "![ ](img/2-1-45.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Lab Estimator API\n",
    "### Launch Cloud Datalab\n",
    "To launch Cloud Datalab:\n",
    "\n",
    "- Step 1\n",
    "Open Cloud Shell. The cloud shell icon is at the top right of the Google Cloud Platform web console:\n",
    "\n",
    "- Step 2\n",
    "In Cloud Shell, type:\n",
    "\n",
    "`gcloud compute zones list`<br>\n",
    "Note: Please pick a zone in a geographically close region from the following: us-east1, us-central1, asia-east1, europe-west1. These are the regions that currently support Cloud ML Engine jobs. Please verify here since this list may have changed after this lab was last updated. For example, if you are in the US, you may choose us-east1-c as your zone.\n",
    "\n",
    "- Step 3\n",
    "In Cloud Shell, type:\n",
    "\n",
    "`datalab create mydatalabvm --zone <ZONE>`<br>\n",
    "Replace <ZONE> with a zone name you picked from the previous step.\n",
    "\n",
    "Note: follow the prompts during this process.\n",
    "\n",
    "Datalab will take about 5 minutes to start.\n",
    "\n",
    "- Step 4\n",
    "Look back at Cloud Shell, and follow any prompts. If asked for a ssh passphrase, just hit return (for no passphrase).\n",
    "\n",
    "- Step 5\n",
    "If necessary, wait for Datalab to finish launching. Datalab is ready when you see a message prompting you to do a \"Web Preview\".\n",
    "\n",
    "- Step 6\n",
    "Click on the Web Preview icon on the top-right corner of the Cloud Shell ribbon. Switch or enter the port 8081.\n",
    "![ ](img/lab-1-4-01.png)\n",
    "![ ](img/lab-1-4-02.png)\n",
    "\n",
    "Note: If the cloud shell used for running the datalab command is closed or interrupted, the connection to your Cloud Datalab VM will terminate. If that happens, you may be able to reconnect using the command ‘datalab connect mydatalabvm' in your new Cloud Shell.\n",
    "\n",
    "### Clone course repo within your Datalab instance\n",
    "To clone the course repo in your datalab instance:\n",
    "\n",
    "- Step 1\n",
    "In Cloud Datalab home page (browser), navigate into \"notebooks\" and add a new notebook using the icon  on the top left.\n",
    "\n",
    "- Step 2\n",
    "Rename this notebook as ‘repocheckout'.\n",
    "\n",
    "- Step 3\n",
    "In the new notebook, enter the following commands in the cell, and click on Run (on the top navigation bar) to run the commands:<br>\n",
    "\n",
    "`%bash\n",
    "git clone https://github.com/GoogleCloudPlatform/training-data-analyst\n",
    "rm -rf training-data-analyst/.git`\n",
    "\n",
    "\n",
    "- Step 4\n",
    "Confirm that you have cloned the repo by going back to Datalab browser, and ensure you see the training-data-analyst directory. All the files for all labs throughout this course are available in this directory.\n",
    "\n",
    "### Machine Learning using tf.estimator\n",
    "- Step 1\n",
    "In Cloud Datalab, click on the Home icon, and then navigate to notebooks/training-data-analyst > courses > machine_learning > deepdive > 03_tensorflow and open b_estimator.ipynb<br>\n",
    "Note: If the cloud shell used for running the datalab command is closed or interrupted, the connection to your Cloud Datalab VM will terminate. If that happens, you may be able to reconnect using the command **‘datalab connect mydatalabvm'** in your new Cloud Shell. Once connected, try the above step again.\n",
    "\n",
    "- Step 2\n",
    "In Datalab, click on Clear | All Cells. Now read the narrative and execute each cell in turn.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train on large datasets with Dataset API\n",
    "![ ](img/2-3-01.png)\n",
    "![ ](img/2-3-02.png)\n",
    "![ ](img/2-3-03.png)\n",
    "![ ](img/2-3-04.png)\n",
    "![ ](img/2-3-05.png)\n",
    "![ ](img/2-3-06.png)\n",
    "![ ](img/2-3-07.png)\n",
    "![ ](img/2-3-08.png)\n",
    "![ ](img/2-3-09.png)\n",
    "![ ](img/2-3-10.png)\n",
    "![ ](img/2-3-21.png)\n",
    "![ ](img/2-3-21.png)\n",
    "![ ](img/2-3-22.png)\n",
    "![ ](img/2-3-23.png)\n",
    "![ ](img/2-3-24.png)\n",
    "![ ](img/2-3-25.png)\n",
    "![ ](img/2-3-26.png)\n",
    "![ ](img/2-3-27.png)\n",
    "![ ](img/2-3-28.png)\n",
    "![ ](img/2-3-29.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Lab Scaling up TensorFlow ingest using batching\n",
    "### Launch Cloud Datalab\n",
    "### Clone course repo within your Datalab instance\n",
    "### Scaling up TensorFlow ingest using batching\n",
    "- Step 1<br>\n",
    "In Cloud Datalab, click on the Home icon, and then navigate to notebooks/training-data-analyst > courses > machine_learning > deepdive > 03_tensorflow and open c_dataset.ipynb.\n",
    "\n",
    "Note: If the cloud shell used for running the datalab command is closed or interrupted, the connection to your Cloud Datalab VM will terminate. If that happens, you may be able to reconnect using the command **‘datalab connect mydatalabvm**' in your new Cloud Shell. Once connected, try the above step again.\n",
    "\n",
    "- Step 2<br>\n",
    "In Datalab, click on Clear | All Cells. Now read the narrative and execute each cell in turn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Big jobs, Distributed training\n",
    "![ ](img/2-5-01.png)\n",
    "![ ](img/2-5-02.png)\n",
    "![ ](img/2-5-03.png)\n",
    "![ ](img/2-5-04.png)\n",
    "![ ](img/2-5-05.png)\n",
    "![ ](img/2-5-06.png)\n",
    "![ ](img/2-5-07.png)\n",
    "![ ](img/2-5-08.png)\n",
    "![ ](img/2-5-09.png)\n",
    "![ ](img/2-5-10.png)\n",
    "![ ](img/2-5-11.png)\n",
    "![ ](img/2-5-12.png)\n",
    "![ ](img/2-5-13.png)\n",
    "![ ](img/2-5-14.png)\n",
    "![ ](img/2-5-15.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Monitoring with TensorBoard\n",
    "![ ](img/2-6-01.png)\n",
    "![ ](img/2-6-02.png)\n",
    "![ ](img/2-6-03.png)\n",
    "![ ](img/2-6-04.png)\n",
    "![ ](img/2-6-05.png)\n",
    "![ ](img/2-6-06.png)\n",
    "![ ](img/2-6-07.png)\n",
    "![ ](img/2-6-08.png)\n",
    "![ ](img/2-6-09.png)\n",
    "![ ](img/2-6-10.png)\n",
    "![ ](img/2-6-21.png)\n",
    "![ ](img/2-6-21.png)\n",
    "![ ](img/2-6-22.png)\n",
    "![ ](img/2-6-23.png)\n",
    "![ ](img/2-6-24.png)\n",
    "![ ](img/2-6-25.png)\n",
    "![ ](img/2-6-26.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Lab Creating a distributed training TensorFlow model with Estimator API\n",
    "**Overview**\n",
    "This lab is part of a lab series, where you go from exploring a taxicab dataset to training and deploying a distributed model with Cloud ML Engine. In the next course of this specialization, we will work on improving the accuracy of this model using feature engineering.\n",
    "### Launch Cloud Datalab\n",
    "### Clone course repo within your Datalab instance\n",
    "### Refactor for Distributed training and monitoring\n",
    "- Step 1<br>\n",
    "In Cloud Datalab, click on the Home icon, and then navigate to notebooks/training-data-analyst > courses > machine_learning > deepdive > 03_tensorflow and open d_traineval.ipynb.\n",
    "\n",
    "Note: If the cloud shell used for running the datalab command is closed or interrupted, the connection to your Cloud Datalab VM will terminate. If that happens, you may be able to reconnect using the command ‘datalab connect mydatalabvm' in your new Cloud Shell. Once connected, try the above step again.\n",
    "\n",
    "- Step 2<br>\n",
    "In Datalab, click on Clear | All Cells. Now read the narrative and execute each cell in turn.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Quiz Estimator API\n",
    "### Question 1\n",
    "What are some of the key goals of the estimator API?\n",
    "- ( ) Create production-ready machine learning models using an API\n",
    "- ( ) Train on large datasets that do not fit in memory\n",
    "- ( ) Quickly monitor your training metrics in Tensorboard\n",
    "- (x) All of the above\n",
    "\n",
    "### Question 2\n",
    "What is one of the largest benefits of the estimator API?\n",
    "- ( ) It automatically tunes your ML model hyperparameters for you\n",
    "- ( ) It requires you to specify which hardware you will run on for the best performance\n",
    "- (x) It abstracts away boilerplate code which saves you time\n",
    "\n",
    "### Question 3\n",
    "What is the right way to call a linear regression model with tf.estimator?\n",
    "- ( ) tf.estimator.line_model\n",
    "- (x) tf.estimator.LinearRegressor\n",
    "- ( ) tf.estimator.regression\n",
    "- ( ) tf.estimator.LinearClassifier\n",
    "\n",
    "### Question 4\n",
    "Inputs to the estimator model are in the form of:\n",
    "- ( ) hyperparameters\n",
    "- ( ) BigQuery datasets\n",
    "- (x) feature columns\n",
    "- ( ) scalars\n",
    "\n",
    "### Question 5\n",
    "Numeric inputs can be passed to a linear regressor as-is, but categorical columns are often:\n",
    "- (x) One-hot encoded\n",
    "- ( ) Uniformly distributed and aggregated first\n",
    "- ( ) Cleansed because of duplicate records\n",
    "- ( ) Not used, only numeric values can be passed\n",
    "\n",
    "### Question 6\n",
    "What is the size of the training dataset (features + labels) in this example?\n",
    "![ ](img/quiz-2-8-01.png)\n",
    "- (x) 6 rows, 3 columns\n",
    "- ( ) 7 rows, 4 columns\n",
    "- ( ) 6 rows, 2 columns\n",
    "- ( ) 6 rows, 4 columns\n",
    "\n",
    "### Question 7\n",
    "In this example, what extra parameters does the DNNRegressor take that the LinearRegressor doesn't?\n",
    "![ ](img/quiz-2-8-02.png)\n",
    "- (x) hidden_units\n",
    "- ( ) featcols\n",
    "- ( ) regression\n",
    "- ( ) neurons\n",
    "\n",
    "### Question 8\n",
    "In what situation do you have to delete the model directory before starting training?\n",
    "- ( ) If you want to automatically checkpoint from an earlier saved model\n",
    "- ( ) If your model is not performing well enough and you need to train for more epochs or with additional examples\n",
    "- (x) If you have changed the model structure from the previous time, for example, you used a DNNRegressor with [64,32] last time and now you are using [32, 16]\n",
    "\n",
    "### Question 9\n",
    "What is the difference between steps and max_steps?\n",
    "![ ](img/quiz-2-8-03.png)\n",
    "- ( ) There is no difference\n",
    "- ( ) Steps means \"train this many steps total\". max_steps means \"train these many additional steps\"\n",
    "- (x) Steps means \"train these many additional steps\". max_steps means \"train up to these many steps total, starting from how many ever steps have been completed so far\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
